# ğŸ¤– ConfiguraciÃ³n de IA - Sintra AI LATAM

Esta guÃ­a te ayuda a configurar los servicios de IA para que tus asistentes funcionen con modelos reales.

## ğŸ¯ Estrategia de Modelos

### Fase Beta (Actual)
- **Proveedor**: Hugging Face (Gratuito/EconÃ³mico)
- **Modelos**: DialoGPT-large, BlenderBot-400M
- **Costo**: ~$0.002 por 1000 tokens
- **Ideal para**: Desarrollo, testing, MVP

### Fase ProducciÃ³n (Futuro)
- **Proveedor**: OpenAI + Anthropic + Hugging Face
- **Modelos**: GPT-4, Claude 3.5 Sonnet, Llama 3.1
- **Costo**: ~$0.03 por 1000 tokens
- **Ideal para**: AplicaciÃ³n en vivo con usuarios reales

## ğŸ”§ ConfiguraciÃ³n RÃ¡pida

### 1. Obtener API Key de Hugging Face

1. Ve a [Hugging Face](https://huggingface.co/)
2. Crea una cuenta gratuita
3. Ve a **Settings** â†’ **Access Tokens**
4. Crea un nuevo token con permisos de **Read**
5. Copia el token

### 2. Configurar Variables de Entorno

```bash
# En tu archivo .env.local
NEXT_PUBLIC_HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxxxxxxx
```

### 3. Verificar ConfiguraciÃ³n

1. Inicia la aplicaciÃ³n: `npm run dev`
2. Ve al dashboard
3. Haz clic en el Ã­cono ğŸ§  (Brain) en el header
4. Haz clic en "Test" para verificar la conexiÃ³n
5. DeberÃ­as ver "âœ… OK" en Hugging Face

## ğŸ§  Funcionamiento del Sistema

### Arquitectura HÃ­brida

```
Usuario envÃ­a mensaje
        â†“
    Servicio de IA
        â†“
Â¿Hugging Face disponible?
    â†™        â†˜
   SÃ­         No
    â†“          â†“
IA Real   SimulaciÃ³n
    â†“          â†“
Respuesta inteligente
```

### Modelos Disponibles

| Modelo | Uso | Velocidad | Calidad |
|--------|-----|-----------|---------|
| **DialoGPT-large** | Principal | Media | Alta |
| **BlenderBot-400M** | Fallback 1 | RÃ¡pida | Media |
| **DialoGPT-medium** | Fallback 2 | RÃ¡pida | Media |

## ğŸ“Š Monitoring y Debugging

### Ver Status en la App

- **Icono ğŸ§  en el header** â†’ Estado actual del sistema
- **Test Connection** â†’ Verificar conectividad
- **Logs en consola** â†’ Ver detalles de respuestas

### Logs TÃ­picos

```bash
# âœ… Funcionando con IA
âœ… AI Response from microsoft/DialoGPT-large in 1247ms

# âš ï¸ Usando fallback
ğŸ”„ Using simulation fallback
AI service failed, falling back to simulation: Model loading
```

## ğŸ›ï¸ PersonalizaciÃ³n Avanzada

### Cambiar Modelos

Edita `src/lib/huggingface-service.ts`:

```typescript
const MODELS = {
  primary: 'microsoft/DialoGPT-large',        // Cambia este
  fallback1: 'facebook/blenderbot-400M-distill',
  fallback2: 'microsoft/DialoGPT-medium',
};
```

### Ajustar ParÃ¡metros

```typescript
parameters: {
  max_length: 500,      // Longitud mÃ¡xima de respuesta
  temperature: 0.7,     // Creatividad (0.1-1.0)
  top_p: 0.9,          // Diversidad (0.1-1.0)
  do_sample: true,     // Activar sampling
}
```

### Personalizar Prompts

Los prompts estÃ¡n en `src/lib/assistant-prompts.ts`:

```typescript
systemPrompt: `Eres SofÃ­a, especialista en redes sociales...`
```

## ğŸš€ OptimizaciÃ³n para ProducciÃ³n

### 1. CachÃ© de Respuestas

```typescript
// TODO: Implementar Redis para cachÃ©
const cachedResponse = await redis.get(`response:${hash}`);
```

### 2. Rate Limiting

```typescript
// TODO: Implementar lÃ­mites por usuario/plan
const canProceed = await checkRateLimit(userId, plan);
```

### 3. MÃºltiples Proveedores

```typescript
// TODO: Agregar OpenAI y Anthropic
const providers = ['huggingface', 'openai', 'anthropic'];
```

## ğŸ” Troubleshooting

### Error: "API token not configured"

**Causa**: Variable de entorno no configurada
**SoluciÃ³n**: 
```bash
# AsegÃºrate de tener en .env.local:
NEXT_PUBLIC_HUGGINGFACE_API_KEY=tu_token_aqui
```

### Error: "Model loading"

**Causa**: El modelo estÃ¡ iniciando en Hugging Face
**SoluciÃ³n**: Espera 30-60 segundos, el sistema usa fallback automÃ¡ticamente

### Error: "429 Too Many Requests"

**Causa**: LÃ­mite de rate de Hugging Face alcanzado
**SoluciÃ³n**: 
- Espera unos minutos
- Considera upgradear a Hugging Face Pro
- El sistema usa simulaciÃ³n como fallback

### Respuestas de Baja Calidad

**Causa**: Modelo no optimizado para espaÃ±ol
**SoluciÃ³n**: 
1. Mejora los prompts en `assistant-prompts.ts`
2. Considera usar modelos especÃ­ficos para espaÃ±ol
3. Ajusta `temperature` y `top_p`

## ğŸ“ˆ Roadmap

### Q1 2024 - Beta
- [x] IntegraciÃ³n Hugging Face
- [x] Sistema de fallback
- [x] Monitoring bÃ¡sico
- [ ] CachÃ© de respuestas
- [ ] Rate limiting

### Q2 2024 - ProducciÃ³n
- [ ] IntegraciÃ³n OpenAI GPT-4
- [ ] IntegraciÃ³n Anthropic Claude
- [ ] Balanceador de carga entre proveedores
- [ ] Analytics avanzados

### Q3 2024 - OptimizaciÃ³n
- [ ] Modelos fine-tuned para LATAM
- [ ] Respuestas multimodales (texto + imÃ¡genes)
- [ ] IA de voz para WhatsApp

## ğŸ’¡ Tips Pro

1. **Usa el simulador para desarrollo** - Es mÃ¡s rÃ¡pido y no consume API calls
2. **Activa IA real para demos** - Impresiona a inversores y clientes
3. **Monitorea el usage** - Hugging Face tiene lÃ­mites gratuitos
4. **Optimiza prompts** - Mejores prompts = mejores respuestas
5. **Planea la migraciÃ³n** - OpenAI/Anthropic para producciÃ³n

## ğŸ†˜ Soporte

Â¿Problemas con la configuraciÃ³n?

- **GitHub Issues**: [repo/issues](https://github.com/Inova117/zerionAI/issues)
- **Email**: soporte@sintra-latam.com
- **WhatsApp**: +52 55 1234 5678

---

**Â¡Tu IA ya estÃ¡ lista para conversar! ğŸ‰**
